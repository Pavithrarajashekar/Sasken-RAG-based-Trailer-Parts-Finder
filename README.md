# Sasken-RAG-based-Trailer-Parts-Finder
**ğŸšš Smart Trailer Parts Finder:** (RAG-based Search & Chatbot)(RAG + Streamlit + Web Scraping)
Smart Trailer Parts Finder is a complete Retrieval-Augmented Generation (RAG) system for finding and querying trailer parts from multiple online sources.
It integrates web scraping, data processing, semantic search, and an LLM-powered chatbot into one streamlined pipeline, accessible through a Streamlit interface.
It integrates live web scraping, data normalization, vector embeddings, and LLaMA 3 responses via Ollama.

âœ¨ Features
1. Automated Web Scraping:
Scrapes trailer part listings from eBay and TrailerPartsUnlimited using Selenium.
Captures title, price, source link, and product image.

2. Data Normalization & Processing:
Merges scraped data from multiple sources.
Cleans and standardizes fields for consistency.

3. Semantic Search with ChromaDB:
Creates vector embeddings via SentenceTransformers (all-MiniLM-L6-v2).
Stores data in ChromaDB for fast similarity search.

4. RAG Chatbot with LLaMA 3 (Ollama):
Retrieves the most relevant product details from ChromaDB.
Uses LLaMA 3 to answer queries based on retrieved data.

5. Interactive Web Interface:
Product Search â€“ Find products by keyword, view details (price, image, source).
Chatbot â€“ Ask product-related questions and get conversational answers.
Secure Login â€“ Restrict access with authentication.
Manual Pipeline Trigger â€“ Run the entire update pipeline from the UI.

## ğŸ“‚ Project Structure
â”œâ”€â”€ Scrapers/
â”‚ â”œâ”€â”€ scrape_ebay.py
â”‚ â””â”€â”€ scrape_trailerpartsunlimited.py
â”‚
â”œâ”€â”€ rag_engine/
â”‚ â”œâ”€â”€ 1merge_and_normalize.py
â”‚ â”œâ”€â”€ 2chunking.py
â”‚ â”œâ”€â”€ 3embed_to_chromadb.py
â”‚ â”œâ”€â”€ 4query_from_chromadb.py
â”‚ â””â”€â”€ 5RAG_chatbot.py
â”‚
â”œâ”€â”€ chromadb/ # Persistent vector store
â”œâ”€â”€ data/ # Product JSON/CSV and chunks
â”œâ”€â”€ logs/ # Scraper logs
â”œâ”€â”€ ui.py # Streamlit frontend
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
## âš™ï¸ Installation
 1. Install dependencies:
    pip install -r requirements.txt
  
 2. Run scrapers (save output in `data/`):
    python Scrapers/scrape_ebay.py
    python Scrapers/scrape_trailerpartsunlimited.py
   
 3. Merge, chunk, embed:
    python rag_engine/1merge_and_normalize.py
    python rag_engine/2chunking.py
    python rag_engine/3embed_to_chromadb.py

 4. Search interface(query from chromaDb)
    python  rag_engine/4query_from_chromadb.py

 5. RAG chatbot
    python  rag_engine/5RAG_chatbot.py

 6. Start Streamlit UI:
    streamlit run ui.py
 
 Default login: `admin` / `password123`


